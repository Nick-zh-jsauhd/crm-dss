# app/app.py
import os
import sys

import pandas as pd
import streamlit as st
import joblib

# ====== è·¯å¾„é…ç½® ======
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
SRC_DIR = os.path.join(PROJECT_ROOT, "src")
sys.path.append(SRC_DIR)

from evaluate_model import evaluate_on_dataframe, load_labeled_data
from rules import classify_customer
from llm_agent import (
    generate_advice_template,
    generate_advice_with_llm,
)

MODEL_PATH = os.path.join(PROJECT_ROOT, "models", "buy_model.pkl")
SAMPLE_DATA_PATH = os.path.join(PROJECT_ROOT, "data", "crm_test_data.csv")
TRAINING_DATA_PATH = os.path.join(PROJECT_ROOT, "data", "crm_training_data.csv")


@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        st.error("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆåœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼špython -m src.train_model")
        st.stop()
    return joblib.load(MODEL_PATH)


def main():
    st.set_page_config(page_title="CRM å†³ç­–æ”¯æŒç³»ç»Ÿ", layout="wide")
    st.title("ğŸ“Š CRM å†³ç­–æ”¯æŒç³»ç»Ÿ - Yannick")
    st.markdown(
        "è¯¥ç³»ç»ŸåŸºäºå†å²æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œä¸ºå®¢æˆ·æˆäº¤æ¦‚ç‡é¢„æµ‹æä¾›æ”¯æŒï¼Œå¹¶ç”Ÿæˆè·Ÿè¿›å»ºè®®ã€‚"
    )

    model = load_model()

    # ============= LLM è®¾ç½® =============
    st.sidebar.header("ğŸ”‘ LLM è®¾ç½®ï¼ˆDeepSeekï¼‰")

    # 1) å°è¯•è¯»å–ç¯å¢ƒå˜é‡ï¼ˆStreamlit Cloud secretsï¼‰
    default_key = os.getenv("DEEPSEEK_API_KEY", "")

    api_key_input = st.sidebar.text_input(
        "è¾“å…¥ä½ çš„ DeepSeek API Keyï¼ˆå¯é€‰ï¼‰",
        type="password",
        help="ä¸å¡«å†™åˆ™ä½¿ç”¨æœåŠ¡å™¨é»˜è®¤é…ç½®ï¼ˆå¦‚æœå·²é…ç½®ï¼‰ï¼›æœ¬åœ°è¿è¡Œæ—¶å¯æ‰‹åŠ¨å¡«å†™ã€‚",
        value=""  # ä¸åœ¨ç•Œé¢é¢„å¡«ï¼Œé¿å…æ³„éœ²
    )

    # åˆå§‹åŒ– session_state
    if "api_key" not in st.session_state:
        st.session_state["api_key"] = ""

    # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡
    if api_key_input:
        st.session_state["api_key"] = api_key_input
    else:
        st.session_state["api_key"] = default_key

    # ============= æ•°æ®æ¥æºé€‰æ‹© =============
    st.sidebar.header("ğŸ“‚ æ•°æ®ä¸é¢„æµ‹")

    data_source = st.sidebar.radio(
        "é€‰æ‹©æ•°æ®æ¥æº",
        ("ä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†", "ä¸Šä¼ è‡ªå®šä¹‰CSV"),
    )

    df = None

    if data_source.startswith("ä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†"):
        # ä½¿ç”¨ä»“åº“å†…è‡ªå¸¦çš„ç¤ºä¾‹æ•°æ®
        if not os.path.exists(SAMPLE_DATA_PATH):
            st.error(
                "ç¤ºä¾‹æ•°æ®é›† data/crm_test_data.csv ä¸å­˜åœ¨ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»º data æ–‡ä»¶å¤¹å¹¶æ”¾å…¥è¯¥ CSV åé‡æ–°éƒ¨ç½²ã€‚"
            )
            return

        df = pd.read_csv(SAMPLE_DATA_PATH)
        st.sidebar.success("å·²åŠ è½½ç¤ºä¾‹æ•°æ®é›†")
    else:
        # ç”¨æˆ·è‡ªå®šä¹‰ä¸Šä¼ 
        uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ å®¢æˆ·ç‰¹å¾æ•°æ®ï¼ˆCSVï¼‰", type=["csv"])
        if uploaded_file is None:
            st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ å¾…é¢„æµ‹çš„å®¢æˆ·æ•°æ®ï¼Œæˆ–é€‰æ‹©â€œä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†â€ã€‚")
            return
        df = pd.read_csv(uploaded_file)
        st.sidebar.success("å·²åŠ è½½è‡ªå®šä¹‰æ•°æ®é›†ã€‚")

    # åˆ°è¿™é‡Œ df ä¸€å®šå·²ç»æœ‰å€¼
    if "customer_id" not in df.columns:
        st.error("æ•°æ®ä¸­å¿…é¡»åŒ…å« 'customer_id' åˆ—ã€‚")
        return

    feature_cols = [c for c in df.columns if c != "customer_id"]
    X = df[feature_cols]

    # ====== é¢„æµ‹ç»“æœç¼“å­˜ ======
    if "pred_df" not in st.session_state:
        st.session_state["pred_df"] = None

    # ====== ç‚¹å‡»æŒ‰é’®è¿è¡Œé¢„æµ‹ ======
    if st.sidebar.button("è¿è¡Œé¢„æµ‹"):
        with st.spinner("æ­£åœ¨è¿è¡Œæ¨¡å‹é¢„æµ‹..."):
            proba = model.predict_proba(X)[:, 1]
            pred = (proba >= 0.5).astype(int)

            df_pred = df.copy()
            df_pred["prob"] = proba
            df_pred["pred_label"] = pred

            df_pred["rule_advice"] = [
                classify_customer(row, p) for (_, row), p in zip(df_pred.iterrows(), proba)
            ]

        st.session_state["pred_df"] = df_pred
        st.success("é¢„æµ‹å®Œæˆï¼")

    # ================= å±•ç¤ºé¢„æµ‹ç»“æœ =================
    if st.session_state["pred_df"] is not None:
        df_pred = st.session_state["pred_df"]

        st.subheader("ğŸ“‹ å®¢æˆ·é¢„æµ‹ç»“æœä¸€è§ˆ")
        st.dataframe(
            df_pred[["customer_id", "prob", "pred_label", "rule_advice"] + feature_cols].head(50),
            use_container_width=True,
        )

        # ========= å•å®¢æˆ·è¯¦æƒ… =========
        st.subheader("ğŸ” å•å®¢æˆ·è¯¦æƒ…ä¸è·Ÿè¿›å»ºè®®")

        customer_ids = df_pred["customer_id"].tolist()
        selected_id = st.selectbox("é€‰æ‹©ä¸€ä¸ªå®¢æˆ·IDæŸ¥çœ‹è¯¦æƒ…", options=customer_ids)

        selected_row = df_pred[df_pred["customer_id"] == selected_id].iloc[0]
        selected_prob = float(selected_row["prob"])
        selected_rule_advice = selected_row["rule_advice"]

        st.markdown("**åŸºç¡€ä¿¡æ¯ä¸æ¨¡å‹ç»“æœ**")
        info_cols = ["customer_id"] + [c for c in feature_cols if c in selected_row.index]
        st.table(selected_row[info_cols].to_frame("å€¼"))

        st.markdown(
            f"**æ¨¡å‹é¢„æµ‹æˆäº¤æ¦‚ç‡ï¼š** `{selected_prob:.2%}`  \n"
            f"**è§„åˆ™å¼•æ“å»ºè®®ï¼š** {selected_rule_advice}"
        )

        # ========= LLM å»ºè®® æŒ‰é’® =========
        if st.button("ç”Ÿæˆæ–‡å­—ç‰ˆè·Ÿè¿›å»ºè®®ï¼ˆDeepSeekï¼‰"):
            api_key = st.session_state.get("api_key", "")

            if api_key:
                with st.spinner("æ­£åœ¨è°ƒç”¨ DeepSeek ç”Ÿæˆå»ºè®®..."):
                    advice = generate_advice_with_llm(
                        selected_row,
                        selected_prob,
                        selected_rule_advice,
                        api_key=api_key,
                    )
            else:
                st.info("æœªè¾“å…¥ DeepSeek API Keyï¼Œå·²ä½¿ç”¨æ¨¡æ¿ç‰ˆå»ºè®®ï¼ˆéå¤§æ¨¡å‹ï¼‰ç”Ÿæˆç»“æœã€‚")
                advice = generate_advice_template(
                    selected_row,
                    selected_prob,
                    selected_rule_advice,
                )

            st.markdown("### ğŸ§  å»ºè®®æ–‡æœ¬")
            st.write(advice)

    # ================= æ¨¡å‹å‡†ç¡®æ€§è¯„ä¼° =================
    st.divider()
    st.header("ğŸ“ˆ æ¨¡å‹å‡†ç¡®æ€§è¯„ä¼°")
    st.markdown(
        "ä¸Šä¼ æˆ–é€‰ç”¨å¸¦ `label` (0/1) çš„æ•°æ®é›†ï¼Œè®¡ç®—å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1ã€ROC AUC ç­‰æŒ‡æ ‡ï¼Œ"
        "ä¾¿äºç›‘æ§æ¨¡å‹æ•ˆæœã€‚"
    )

    eval_source = st.radio(
        "é€‰æ‹©è¯„ä¼°æ•°æ®æ¥æº",
        ("ä½¿ç”¨æœ¬åœ°è®­ç»ƒé›† (data/crm_training_data.csv)", "ä¸Šä¼ è‡ªå®šä¹‰å¸¦ label çš„ CSV"),
        key="eval_source",
    )

    eval_df = None
    if eval_source.startswith("ä½¿ç”¨æœ¬åœ°è®­ç»ƒé›†"):
        if os.path.exists(TRAINING_DATA_PATH):
            try:
                eval_df = load_labeled_data(TRAINING_DATA_PATH)
                st.caption(f"å·²è½½å…¥: {TRAINING_DATA_PATH}")
            except Exception as e:
                st.error(f"åŠ è½½æœ¬åœ°è®­ç»ƒé›†å¤±è´¥ï¼š{e}")
        else:
            st.error("æœªæ‰¾åˆ° data/crm_training_data.csvï¼Œè¯·å…ˆå‡†å¤‡å¸¦ label çš„è¯„ä¼°æ•°æ®ã€‚")
    else:
        eval_file = st.file_uploader("ä¸Šä¼ å¸¦ label çš„ CSV (é¡»åŒ…å« customer_id, label åˆ—)", type=["csv"])
        if eval_file is not None:
            eval_df = pd.read_csv(eval_file)
            missing = [c for c in ("customer_id", "label") if c not in eval_df.columns]
            if missing:
                st.error(f"ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing)}")
                eval_df = None

    if st.button("è¿è¡Œæ¨¡å‹è¯„ä¼°", key="run_eval"):
        if eval_df is None:
            st.warning("è¯·å…ˆé€‰æ‹©æœ‰æ•ˆçš„è¯„ä¼°æ•°æ®ã€‚")
        else:
            with st.spinner("æ­£åœ¨è®¡ç®—è¯„ä¼°æŒ‡æ ‡..."):
                try:
                    metrics = evaluate_on_dataframe(model, eval_df)
                except Exception as e:
                    st.error(f"è¯„ä¼°å¤±è´¥ï¼š{e}")
                else:
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("å‡†ç¡®ç‡", f"{metrics['accuracy']:.2%}")
                    col2.metric("ç²¾ç¡®ç‡", f"{metrics['precision']:.2%}")
                    col3.metric("å¬å›ç‡", f"{metrics['recall']:.2%}")
                    auc_value = metrics.get("roc_auc")
                    if auc_value is not None:
                        col4.metric("ROC AUC", f"{auc_value:.3f}")
                    else:
                        col4.metric("ROC AUC", "N/A")

                    st.metric("F1 åˆ†æ•°", f"{metrics['f1']:.2%}")

                    st.markdown("**æ··æ·†çŸ©é˜µ (è¡Œ=çœŸå®å€¼, åˆ—=é¢„æµ‹å€¼)**")
                    cm = metrics["confusion_matrix"]
                    cm_df = pd.DataFrame(
                        cm,
                        columns=["é¢„æµ‹:è´Ÿç±»(0)", "é¢„æµ‹:æ­£ç±»(1)"],
                        index=["çœŸå®:è´Ÿç±»(0)", "çœŸå®:æ­£ç±»(1)"],
                    )
                    st.dataframe(cm_df)

                    st.markdown("**åˆ†ç±»æŠ¥å‘Š**")
                    st.text(metrics["classification_report"])

if __name__ == "__main__":
    main()
